### 长短期记忆网络使用案例

1. 文本生成
2. 命名实体识别
3. 词嵌入

   - 从词袋（bag of words）到词嵌入
   - 用m维的实值向量表示单词（概念）
   - 连续词袋（CBOW）模型（word2vec）
     - 输入、输出 词 x、y是one-hot编码
     - 所有输入此共享隐藏层
   - 词嵌入的卓越性
     - 使用词向量进行简单的代数运算
4. 神经网络模型

   - N-gram模型
   - 神经语言模型
5. 基于RNN的语言模型

   - 前馈神经网络的局限性：必须固定上下文长度
   - RNN解决办法
     - 维护一个上下文表示并随着时间更新
6. 学习视觉语言对齐

   - 区域CNN+双向RNN

     - 通过一个共同的多模式嵌入空间将这两种方式联系起来
7.   学习生成图像描述
   - 用图像训练CNN+用句子训练RNN
     - RNN接受一个单词和之前的上线文，输出下一个单词的分布
     - 图片信息一开始就输入到RNN
     - START和END是特殊标志符

8. 神经网络及深度学习总结
   - 通用近似：生成神经网络可以逼近任何函数
   - 到目前为止，反向传播是多层神经网络最重要的训练方案
   - 深度学习，即用大数据训练的深度神经网络，效果非常好
   - 结合其他机器学习模型的神经网络取得进一步成功

